# CD
# Proyecto: ClasificaciÃ³n de CÃ¡ncer de Mama con Ãrbol de DecisiÃ³n

Este proyecto implementa un **modelo de Ãrbol de DecisiÃ³n** para la **clasificaciÃ³n de tumores de mama** utilizando el conjunto de datos de **CÃ¡ncer de Mama de Wisconsin**. Se entrena el modelo, se ajustan hiperparÃ¡metros con `GridSearchCV`, se evalÃºa con datos de prueba y se visualiza la estructura del Ã¡rbol de decisiÃ³n.

## ğŸ“‚ **Estructura del Proyecto**

```
ğŸ“‚ models            # Carpeta donde se guardan los modelos entrenados
ğŸ“‚ notebooks         # Carpeta opcional para anÃ¡lisis exploratorio
ğŸ“‚ data              # Carpeta opcional para almacenar datasets
ğŸ“œ main.py           # Script principal que ejecuta entrenamiento y evaluaciÃ³n
ğŸ“œ train_model.py    # Script para entrenamiento del modelo y ajuste de hiperparÃ¡metros
ğŸ“œ test_model.py     # Script para evaluar el modelo en los datos completos
ğŸ“œ predictor.py      # Script para hacer predicciones individuales y visualizar el Ã¡rbol de decisiÃ³n
ğŸ“œ README.md         # DocumentaciÃ³n del proyecto
```

---

## ğŸ“Š **Dataset**
El dataset utilizado es el **CÃ¡ncer de Mama de Wisconsin**, disponible en `sklearn.datasets.load_breast_cancer()`. Contiene 569 muestras con **30 caracterÃ­sticas** que describen propiedades del tumor, y una etiqueta de clasificaciÃ³n:

- **0 â†’ Maligno**
- **1 â†’ Benigno**

El dataset ya estÃ¡ preprocesado y listo para ser utilizado en modelos de Machine Learning.

---

## ğŸ”§ **Entrenamiento del Modelo (`train_model.py`)**

### ğŸ”¹ **Preprocesamiento de Datos**
1. Se carga el dataset con `load_breast_cancer()`.
2. Se divide en **80% datos de entrenamiento** y **20% datos de prueba** con `train_test_split()`.
3. Se **escalan las caracterÃ­sticas** con `StandardScaler()` para mejorar el rendimiento del modelo.

### ğŸ”¹ **DefiniciÃ³n del Modelo y BÃºsqueda de HiperparÃ¡metros**
Se entrena un **Ãrbol de DecisiÃ³n (`DecisionTreeClassifier`)**, ajustando los hiperparÃ¡metros con `GridSearchCV`.

#### **ğŸ“Œ HiperparÃ¡metros Evaluados:**
```python
param_grid = {
    'criterion': ['gini', 'entropy'],      # FunciÃ³n de evaluaciÃ³n del Ã¡rbol
    'max_depth': [None, 10, 20, 30],       # Profundidad mÃ¡xima del Ã¡rbol
    'min_samples_split': [2, 5, 10],       # MÃ­nimo de muestras para dividir un nodo
    'min_samples_leaf': [1, 2, 4]          # MÃ­nimo de muestras en cada hoja
}
```

### ğŸ”¹ **Â¿CÃ³mo Funciona `GridSearchCV`?**
`GridSearchCV` busca la mejor combinaciÃ³n de hiperparÃ¡metros evaluando cada configuraciÃ³n con **validaciÃ³n cruzada (`cv=5`)**. Se utiliza `n_jobs=-1` para aprovechar todos los nÃºcleos disponibles y **optimizar la bÃºsqueda**.

```python
grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train_scaled, y_train)
```

ğŸ“Œ **Resultado:** Se selecciona el mejor modelo (`best_clf`), que luego se **guarda en `models/arbol_decision.pkl`** para futuras predicciones.

### ğŸ”¹ **EvaluaciÃ³n del Modelo**
DespuÃ©s del entrenamiento, se evalÃºa el modelo con los datos de prueba:
```python
print("Matriz de ConfusiÃ³n:")
print(confusion_matrix(y_test, y_pred))
print("Reporte de ClasificaciÃ³n:")
print(classification_report(y_test, y_pred))
```
Esto muestra la **precisiÃ³n, recall, F1-score** y otras mÃ©tricas clave.

---

## ğŸ§ª **EvaluaciÃ³n del Modelo (`test_model.py`)**
Este script carga el modelo entrenado (`arbol_decision.pkl`) y lo evalÃºa con **todo el dataset**.

- Se cargan los datos y se **escalan nuevamente** con el mismo `StandardScaler()`.
- Se cargan los pesos del modelo con `joblib.load()`.
- Se hacen predicciones sobre `X_scaled`.
- Se generan mÃ©tricas de evaluaciÃ³n con `classification_report()` y `confusion_matrix()`.

ğŸ“Œ **Esto verifica si el modelo generaliza bien a datos nuevos.**

---

## ğŸ” **Predicciones y VisualizaciÃ³n (`predictor.py`)**
Este script selecciona una muestra aleatoria, **predice su clase y muestra el Ã¡rbol de decisiÃ³n con los nodos resaltados**.

1. **Carga el modelo entrenado** (`arbol_decision.pkl`).
2. **Toma una muestra aleatoria** y obtiene su ruta en el Ã¡rbol.
3. **Dibuja el Ã¡rbol de decisiÃ³n** con `plot_tree()`.
4. **Resalta los nodos del camino de decisiÃ³n** en rojo.

```python
for node_id in node_indicator.indices:
    plt.gca().texts[node_id].set_bbox(dict(facecolor="red", alpha=0.2, edgecolor="black", boxstyle="round,pad=0.2"))
```

ğŸ“¸ **La imagen del Ã¡rbol se guarda en `models/arbol_decision_marcado.png`.**

ğŸ“Œ **Esto permite visualizar cÃ³mo el modelo toma decisiones.**

---

## ğŸš€ **EjecuciÃ³n del Proyecto**
### **1ï¸âƒ£ Entrenar el Modelo**
```bash
python main.py
```
Esto entrenarÃ¡ el modelo, guardarÃ¡ los pesos y evaluarÃ¡ el rendimiento.

### **2ï¸âƒ£ Hacer Predicciones**
```bash
python predictor.py
```
Esto imprimirÃ¡ la **predicciÃ³n de una muestra aleatoria** y generarÃ¡ la imagen del Ã¡rbol con los nodos resaltados.

---

## ğŸ›  **Requisitos y LibrerÃ­as**
Antes de ejecutar el proyecto, instala las dependencias con:
```bash
pip install -r requirements.txt
```

LibrerÃ­as utilizadas:
- `numpy`, `pandas`
- `scikit-learn`
- `matplotlib`
- `joblib`

---

## ğŸ“Œ **ConclusiÃ³n**
Este proyecto muestra cÃ³mo entrenar, optimizar y evaluar un **Ãrbol de DecisiÃ³n** para la clasificaciÃ³n de tumores de mama. AdemÃ¡s, permite visualizar el proceso de decisiÃ³n del modelo, lo que es Ãºtil para entender cÃ³mo toma sus predicciones.


